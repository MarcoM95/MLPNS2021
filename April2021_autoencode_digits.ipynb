{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "April2021 autoencode_digits.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarcoM95/MLPNS2021/blob/main/April2021_autoencode_digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4Hqug0lfaG9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72ad2f5b-ce61-4c3f-e0bd-0b94e1b77deb"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense#, Dropout, Flatten\n",
        "#from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "import glob\n",
        "import pylab as pl\n",
        "from PIL import Image\n",
        "\n",
        "%pylab inline\n"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['ndim']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8mW27gnf7U4"
      },
      "source": [
        "# 1. change kernel to GPU \n",
        "go to runtime -> change runtime type -> GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPgi-4gMgRTo"
      },
      "source": [
        "# digits first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3UsLpN7gRJy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "88dfb748-151a-45a0-d842-7123f9af9269"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "img_rows, img_cols = 28, 28\n",
        "pl.imshow(x_train[0])\n",
        "pl.axis('off')\n",
        "intialshape = x_train[0].shape\n",
        "ndim = np.prod(x_train[0].shape)\n",
        "x_train.shape"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAG3UlEQVR4nO3df6jddR3H8Xt275zdXOpamoLN2zbb0KXVqA3HFsSWf/RHEbch/tOiP9KmVAssiX6xwiCEtZZ/CDaFLLti5B+ljIgh5G6ZYVTkwm2Ebt26u2zWXG2ec/qrP4T7fd92dy/3de4ejz/32veeL4zn/cI+nHNa3W63D8izYK5vAJicOCGUOCGUOCGUOCHUQDVuXjDsv3Jhlu3rjLQm+3NPTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgg1MNc3wOu1Bup/kv63LJ3V13/h89c2bu3BTnntsuV/L/fBO1rl/rf7Lmrcnlv7aHntePtUub9vZEe5r/jcgXKfC56cEEqcEEqcEEqcEEqcEEqcEEqcEMo55yT6V68s9+6iheV+dNNl5X56XfOZ3JJL6/O6p2+sz/vm0s9fXVzu3/ruLeU+uuaRxu3w2dPltfeObS73q5/ulnsiT04IJU4IJU4IJU4IJU4IJU4IdUEepbTf/+5yv2/vnnK/bmHzW5vms7Pddrl/effHy33gVH2csX5ke+O2+OXXymsXjddHLYPPjpZ7Ik9OCCVOCCVOCCVOCCVOCCVOCCVOCHVBnnMueuFouf/239eU+3ULx2bydmbUjmPryv3Qv+qP1ty7/LHG7WSnPqe88ju/KvfZ1HtvCJuaJyeEEieEEieEEieEEieEEieEEieEanW7zSdEmxcMz8fjoylNbFtf7q/cUn98Zf/vLyn35+/Yfc739D87x99Z7r/ZVJ9jtk+cLPfu+hsbtyN3lZf2Dd36fP0XmNS+zsik343oyQmhxAmhxAmhxAmhxAmhxAmhxAmhnHNOQ//SN5d7+/hEuR9+pPms8o8bHyyvfe837yz3K/bM3XsqmR7nnNBjxAmhxAmhxAmhxAmhxAmhxAmhLsjPrT1f7fHj53X92Vem//2e19/2p3L/x/399Q/o1N+xSQ5PTgglTgglTgglTgglTgglTgjlKGUOrL77YOO2bc0Hymu/v+wX5b5p+NPlvvjRA+VODk9OCCVOCCVOCCVOCCVOCCVOCCVOCOWccw5UX8N3/PbV5bV/feJ0uX9h58Pl/sWPfaTcu7+7tHG75hvPlNf2FR+zyrnz5IRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQvgKwx0x8Yn25/+Ar3y73oYGLp/3a1z+8vdxXPnCs3F87dGTarz2f+QpA6DHihFDihFDihFDihFDihFDihFDOOeeZ7s03lfub7n2p3H/49qem/dqrfvnJcn/H15rfx9rX19fX/suhab92L3POCT1GnBBKnBBKnBBKnBBKnBBKnBDKOecFpv/KK8r96NYVjdvo3bvKaxdM8bv+tsNbyv3khuPlPl8554QeI04IJU4IJU4IJU4IJU4I5SiF/9uPX6q/AnCwdVG5v9o9U+4fuvMzzT/7J6Pltb3MUQr0GHFCKHFCKHFCKHFCKHFCKHFCqIG5vgFmVmdD/dGYLw7XXwF4w01HGrepzjGnsnviXeU++NNnz+vnzzeenBBKnBBKnBBKnBBKnBBKnBBKnBDKOWeY1tobyv3gXfVZ4wM3P1TuGy+u31N5Pv7TPVvuByaG6h/QOTaDd9P7PDkhlDghlDghlDghlDghlDghlDghlHPOWTAwtKzcX9x2deP21a0/Kq/96CXj07qnmXDP2Npy379rXblf/lD9ube8nicnhBInhBInhBInhBInhBInhHKUMomBa99W7iffc1W5b/36k+X+qcseP+d7mik7jtXHHc98r/m4ZMneX5fXXt5xVDKTPDkhlDghlDghlDghlDghlDghlDgh1Lw95xy46q2N28SDbyyvvX1of7nfunhsWvc0E7a/vKHcn7u//grApY/9odyX/NNZZQpPTgglTgglTgglTgglTgglTgglTggVe8555oP1xzCe+exEud+z4meN25Y3nJrWPc2Usfbpxm3jEzvKa1d96c/lvuREfU7ZKVeSeHJCKHFCKHFCKHFCKHFCKHFCKHFCqNhzziMfrn9vHFwzMmuvvefE8nLftX9LubfarXJftfNw47ZybLS8tl2uzCeenBBKnBBKnBBKnBBKnBBKnBBKnBCq1e12G8fNC4abR2BG7OuMTHow7skJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocqPxgTmjicnhBInhBInhBInhBInhBInhPov4pAh9ImItfUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kgzSExkgQ9Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0e34ee2-8d6d-4c47-d9bb-d6a759cf28ea"
      },
      "source": [
        "x_train.dtype, x_train.max(), x_train.min()\n"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('uint8'), 255, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KhWi6TGhdv1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e2dfb5c-6fbb-4a46-9233-fd2bafcf68b3"
      },
      "source": [
        "x_train = (x_train.astype(float) / 255).reshape(len(x_train), ndim)\n",
        "x_test = (x_test.astype(float) / 255).reshape(len(x_test), ndim)\n",
        "x_train.shape, x_test.shape"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (10000, 784))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHFbH3TpoRtg",
        "outputId": "319f86fc-9017-482f-eee5-a386a71555f3"
      },
      "source": [
        "x_train.max()"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E15XyNA9oe71",
        "outputId": "612fb306-03ec-4b52-e03e-2f013c3ef76d"
      },
      "source": [
        "x_test.max()"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huWbhFyJK4Vn"
      },
      "source": [
        "# create a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zR7X6JuK7WW"
      },
      "source": [
        "#keras.models?"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdDtlC4NhO5o",
        "outputId": "34aa9d9f-c7f4-48ef-e1d1-27f94607abbc"
      },
      "source": [
        "ndim"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eheFp_InJiao",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "3b2f97a2-2457-4eaf-dcbf-a59b133480af"
      },
      "source": [
        "model_digits64 = Sequential()\n",
        "## encoder\n",
        "# input layer and the output size\n",
        "model_digits64.add(Dense(128, activation='relu', input_dim = ndim))\n",
        "  #compression layer\n",
        "model_digits64.add(Dense(64, activation='relu'))\n",
        "## deencoder\n",
        "#decompression layer, same size as in the encoder\n",
        "model_digits64.add(Dense(128, activation='relu'))\n",
        "#output layer, same size as input\n",
        "model_digits64.add(Dense(ndim, activation='linear'))\n",
        "\n",
        "\n",
        "#alternative syntax\n",
        "\"\"\"\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "encoder = Model(input_img, encoded)\n",
        "\n",
        "# create a placeholder for an encoded (32-dimensional) input\n",
        "encoded_input = Input(shape=(encoding_dim,))\n",
        "# retrieve the last layer of the autoencoder model\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "# create the decoder model\n",
        "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
        "\"\"\""
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nencoded = Dense(encoding_dim, activation=\\'relu\\')(input_img)\\n# \"decoded\" is the lossy reconstruction of the input\\ndecoded = Dense(784, activation=\\'sigmoid\\')(encoded)\\n\\nautoencoder = Model(input_img, decoded)\\n\\nencoder = Model(input_img, encoded)\\n\\n# create a placeholder for an encoded (32-dimensional) input\\nencoded_input = Input(shape=(encoding_dim,))\\n# retrieve the last layer of the autoencoder model\\ndecoder_layer = autoencoder.layers[-1]\\n# create the decoder model\\ndecoder = Model(encoded_input, decoder_layer(encoded_input))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8x2nldcvmgqX",
        "outputId": "0e19e875-badd-4860-d144-3aea15838e89"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlxeNjj0nmHI",
        "outputId": "9ed62f37-23df-4607-9ce2-b751a7736c64"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-jfXI90M0yE"
      },
      "source": [
        "### regression\n",
        "- loss='mean_squared_error' L2: default loss to use for regression problems. => linear activation function in output layer, one node out\n",
        "\n",
        "alternatives:  loss='mean_squared_logarithmic_error', 'mean_absolute_error' (which is L1 instead of L2)\n",
        "### binary classification\n",
        "\n",
        "- loss='binary_crossentropy' => sigmoid activation function in output layer, one node out\n",
        "\n",
        "alternatives: 'hinge'\n",
        "\n",
        "### multiclass classification\n",
        "categorical encoded as numerical\n",
        "- loss='categorical_crossentropy' => softmax n nodes out\n",
        "\n",
        "onehot encoded categoridal\n",
        "- 'parse_categorical_crossentropy' => softmax n nodes out\n",
        "\n",
        "- 'kullback Leibler Divergence Loss' => probabilistic categorical classification; log(P/Q)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZORHj6SPha0"
      },
      "source": [
        "## optimizers\n",
        "- SGD: stocastic gradient descent \n",
        "    - nesterov=True -> momentum inclusion\n",
        "- adam: Adaptive moment estimation. **good in most cases**\n",
        "- adagrad: different steps for different parameters based on frequency (binary input) well-suited for dealing with sparse data.\n",
        "\n",
        "- adaDelta: like adagrad but compensated for vanishing learning rate problem\n",
        "\n",
        "momentum refers to looking one step back and make a decision that includes the slope there\n",
        "\n",
        "### parameter:\n",
        "generally you need to adjust the learning rate which is how much you change the parameters by at each step. \n",
        "keras.optimizers.Adam(lr=0.001)\n",
        "\n",
        "\n",
        "https://gitcdn.xyz/cdn/Tony607/blog_statics/e1a0b1e060e783bd1978a141acff897ae71bd021/images/optimizer/optimizer.gif"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MePeWiOJJsTi"
      },
      "source": [
        "# choose the optimizer and loss appropriately!\n",
        "model_digits64.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwCCOxn1Juxl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e3ad87f-c1bf-45d1-ae51-281048a6bab3"
      },
      "source": [
        "print(model_digits64.summary())"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_93 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_94 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_95 (Dense)             (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_96 (Dense)             (None, 784)               101136    \n",
            "=================================================================\n",
            "Total params: 218,192\n",
            "Trainable params: 218,192\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsWOelvIJun2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "24ce9477-0e4a-426d-b666-a29b0942e32f"
      },
      "source": [
        "history64 = model_digits64.fit(x_train, x_train, \n",
        "                               validation_data=(x_test, x_test),\n",
        "                               epochs=20, batch_size=100, verbose=1)"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-179-b745c42dc151>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history64 = model_digits64.fit(x_train, x_train, \n\u001b[1;32m      2\u001b[0m                                \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                epochs=20, batch_size=100, verbose=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:756 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:1569 sparse_categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits, axis=axis)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:4941 sparse_categorical_crossentropy\n        labels=target, logits=output)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py:4241 sparse_softmax_cross_entropy_with_logits_v2\n        labels=labels, logits=logits, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py:4156 sparse_softmax_cross_entropy_with_logits\n        logits.get_shape()))\n\n    ValueError: Shape mismatch: The shape of labels (received (78400,)) should equal the shape of logits except for the last dimension (received (100, 784)).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJO05FMnRGtP"
      },
      "source": [
        "# always look at the loss!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhfIAie1Jucz"
      },
      "source": [
        "pl.plot(np.array(history64.history['loss']))\n",
        "pl.ylabel('loss')\n",
        "pl.xlabel('iteration')\n",
        "#pl.yscale('log')\n",
        "#pl.xscale('log')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnbDdWi4NxBj"
      },
      "source": [
        "The loss fuctionis plotted and because it is still decreasingn quite rapidly (slope of the curve not near 0 yet) I know I did not run enough epochs. Try and run for 200 epochs!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGTPRyFgRQTF"
      },
      "source": [
        "# predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7exTCDcJKhU_"
      },
      "source": [
        "output_image64 = model_digits64.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeFEGpTul4U6"
      },
      "source": [
        "def compareinout(i, outim, testimg, initialshape=(28,28)):\n",
        "  fig = pl.figure(figsize(10,5))\n",
        "  ax = fig.add_subplot(121) \n",
        "  ax.imshow(testimg[i].reshape(initialshape) , cmap=\"bone\")\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "  ax = fig.add_subplot(122) \n",
        "  ax.imshow(outim[i].reshape(initialshape) , cmap=\"bone\")\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3hzx41EKhOj"
      },
      "source": [
        "for i in range(10):\n",
        "  compareinout(i, output_image64, x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whLydcJrM7t6"
      },
      "source": [
        "This is a rather bad result. Let me see if I can improve it . The images are too detailed. I can treat the problem as a binary problem to derice some detail. To approach a binary classifier I switch the activation function in the last layer to sigmoid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsvBeF_nSJTO"
      },
      "source": [
        "# change loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDXyqX7WKhHu"
      },
      "source": [
        "# choose the optimizer and loss appropriately!\n",
        "model_digits64_sig = Sequential()\n",
        "## encoder.....\n",
        "model_digits64_sig.add(Dense(ndim, activation=...\n",
        "model_digits64_sig.compile(optimizer=\"adadelta\", loss=..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbxiT8xdKhC8"
      },
      "source": [
        "history64_sig = model_digits64_sig.fit(x_train, x_train, \n",
        "                                       validation_data=(x_test, x_test), \n",
        "                                       epochs=..., batch_size=100, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQFxJHtbR2RV"
      },
      "source": [
        "pl.plot(np.array(history64_sig.history['loss']))\n",
        "pl.ylabel('loss')\n",
        "pl.xlabel('iteration')\n",
        "#pl.yscale('log')\n",
        "#pl.xscale('log')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZipOD2qLNYQq"
      },
      "source": [
        "The loss fuctionis plotted and because it is still decreasingn quite rapidly (slope of the curve not near 0 yet) I know I did not run enough epochs. Try and run for 200 epochs!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yOJ8s_xR2L3"
      },
      "source": [
        "output_image64_sig = model_digits64_sig.predict(x_test)\n",
        "for i in range(10):\n",
        "  compareinout(i, output_image64_sig, x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A14pdeQNOb8"
      },
      "source": [
        "Much better! Let me choose a loss fuctio that is more appropriate for a nbinary classificaton."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBCGc4CLTXJ9"
      },
      "source": [
        "# sigmoid and binary cross entropy loss\n",
        "model_digits64_bce = model_digits64_sig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH8X_lDVTlCs"
      },
      "source": [
        "model_digits64_bce.compile(optimizer=\"adadelta\", loss=\"binary_crossentropy\")\n",
        "history64_bce = model_digits64_bce.fit(x_train, x_train, \n",
        "                                       validation_data=(x_test, x_test), \n",
        "                                       epochs=..., batch_size=100, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g94anP0NT4ET"
      },
      "source": [
        "pl.plot(np.array(history64_bce.history['loss']))\n",
        "pl.ylabel('loss')\n",
        "pl.xlabel('iteration')\n",
        "#pl.yscale('log')\n",
        "#pl.xscale('log')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4jlTB2zN_0Y"
      },
      "source": [
        "This loss fuction is also decreasing to steeply. Too few epochs!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HuqPELWT380"
      },
      "source": [
        "output_image64_bce = model_digits64_bce.predict(x_test)\n",
        "for i in range(10):\n",
        "  compareinout(i, output_image64_bce, x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvSx1rU4OHrp"
      },
      "source": [
        "This is a pretty good result!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yWtDsH3T30C"
      },
      "source": [
        "pl.plot(np.array(history64.history['loss']), label=\"linear\")\n",
        "pl.plot(np.array(history64_sig.history['loss']), label=\"sigmoid\")\n",
        "pl.plot(np.array(history64_bce.history['loss']), label=\"bce\")\n",
        "pl.ylabel('loss')\n",
        "pl.xlabel('iteration')\n",
        "pl.legend()\n",
        "pl.title(\"the 3 loss functions\")\n",
        "pl.figure()\n",
        "pl.plot(np.array(history64.history['loss']), label=\"linear\")\n",
        "pl.plot(np.array(history64_sig.history['loss']), label=\"sigmoid\")\n",
        "pl.plot(np.array(history64_bce.history['loss']), label=\"bce\")\n",
        "pl.ylabel('loss')\n",
        "pl.xlabel('iteration')\n",
        "pl.xscale('log')\n",
        "pl.yscale('log')\n",
        "pl.legend()\n",
        "pl.title(\"the 3 loss functions, log scale\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXbrVpAUOeJF"
      },
      "source": [
        "All loss functions plotted: topin natural, bottomin logscale for enhanced visibility. It does not look like any of them is done learning (all decreasing rapidly still), especially the one for the the sigmoid-based mean square error loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWUnoBqkKg9K"
      },
      "source": [
        "# try more compression\n",
        "\n",
        "Now we shrink the bottle neck to 16 neurons: a much more ambitions model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXbjHrYSfwIP"
      },
      "source": [
        "model_digits = Sequential()\n",
        "#encoder...\n",
        "#bottle neck\n",
        "model_digits.add(Dense(16, activation='relu'))\n",
        "#decoder...\n",
        "model_digits.add(Dense(ndim, activation='sigmoid'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6lGMsQki6RC"
      },
      "source": [
        "model_digits.compile(optimizer=\"adadelta\", loss=\"binary_crossentropy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QXiwgL0kPsy"
      },
      "source": [
        "print(model_digits.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65mlyV5hj8Od"
      },
      "source": [
        "history = model_digits.fit(x_train, x_train, epochs=200, batch_size=100, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAbZDuXOlCZi"
      },
      "source": [
        "pl.plot(np.array(history.history['loss']))\n",
        "pl.yscale('log')\n",
        "pl.xscale('log')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNcw-N9EPxib"
      },
      "source": [
        "the loss fuction: once again it did not finish learning. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31mTTaI4mCKw"
      },
      "source": [
        "output_image = model_digits.predict(x_test)\n",
        "\n",
        "for i in range(10):\n",
        "  compareinout(i, output_image, x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_tHRpkkP1y8"
      },
      "source": [
        "The result is not bad! The decoder can recreate the image from only 16 numbers!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNcgMuEWd_m-"
      },
      "source": [
        "# Extract feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHA4zE6xmacQ"
      },
      "source": [
        "from keras import backend as K\n",
        "# input placeholder\n",
        "inp = model_digits.input                   \n",
        "# extract the bottle neck outputs\n",
        "outputs = model_digits.layers[3].output     \n",
        "# create a function to evaluate the output of the bottle neck layer for a given input\n",
        "functors = K.function([inp], [outputs])    \n",
        "\n",
        "# Testing\n",
        "layer_outs = functors(x_test[:1])\n",
        "pl.imshow(layer_outs[0]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR-aIb-XQQhY"
      },
      "source": [
        "This is the reducted representation of the first image in the test sample: a 16-values representation of the NxN pixel image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoT7vdpjWfk8"
      },
      "source": [
        "def compareinout_encoded(i, outim, testimg, initialshape=(28,28)):\n",
        "  fig = pl.figure(figsize(10,5))\n",
        "  ax = fig.add_subplot(131) \n",
        "  ax.imshow(testimg[i].reshape(initialshape) , cmap=\"bone\")\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "  ax = fig.add_subplot(132)\n",
        "  pl.imshow(functors(testimg[i:i+1])[0])\n",
        "  pl.yticks([])\n",
        "  ax = fig.add_subplot(133) \n",
        "  ax.imshow(outim[i].reshape(initialshape) , cmap=\"bone\")\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvFp8cTbcdKa"
      },
      "source": [
        "for i in range(10):\n",
        "  compareinout_encoded(i, output_image, x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivBrwoxqddZv"
      },
      "source": [
        "*left*: original image\n",
        "\n",
        "*center*: compressed representation\n",
        "\n",
        "right: predicted image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GODceYH0DzfK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}